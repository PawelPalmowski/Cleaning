
Getting and cleaning data cours project

The script:

Comment lines split the code into 10 sections:
#Download the training dataset
- downloading the training dataset (url: https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip)
#Unzip the training dataset
- unziping it to the working directory
- creating a subdirectory called "dataset/UCI HAR Dataset" (data files are distributed between two subdirectories: "train" and "test")
#Loading datasets
- loading data from X_train and X_test files
#Adding labels
- labeling columns based on features.txt (dataset/UCI HAR Dataset)
- appending columns with subject nr and activity code, based on subject_test|training.txt and y_test|training.txt (columns named: subject and activity)
#Merging datasets
- merging X_train and X_test into "dataset" (X_train and X_test are removed to save resources)
#Adding descriptive activity name
- replacing activity code with activity labels based on activity_labels.txt (temporary objects removed to save resources)
#Extracting mean and stdev
- subseting columns of interest (name contains "meaan()" or "std()"), "subject" and "activity" columns included, temporary objects removed
#Creating a tidy dataset
- grouping dataset by subject or activity
- summarizing to get means for all columns (saved to object: sub-when grouped by subject and act-when grouped by ativity), "dataset" is removed
- first column (subject|activity) of sub|act is converted to character
- renaming first column of sub and act
- merging sub and act to tidy_dataset, sub and act removed
#Save the tidy dataset
- saving the tidy dataset in working directory (tidy_dataset.txt)
#Cleaning the workspace
- removing all objects
